camera_polygons<-do.call("rbind",camera_polygons)
# AN ID TO KEEP TRACK OF PATCH/SITE/CAMERA
camera_polygons$id<- paste(camera_polygons$patch,camera_polygons$camera_site,camera_polygons$camera,sep="-")
# FACTOR TO KEEP ORDER AS IT WAS
camera_polygons$id<- factor(camera_polygons$id,levels=unique(camera_polygons$id))
# BREAK UP THE DATA.FRAME BY EACH PATCH/SITE/CAMERA COMBINATION
camera_polygons <- split(camera_polygons, camera_polygons$id)
# PROCESS INDVIDUAL CAMERA POLYGONS
camera_polygons <- lapply(camera_polygons, function(x)
{
tmp<- Polygon(x[,c(4,5)])
Polygons(list(tmp),as.character(unique(x[,6])))
})
# MAKE A SPATIAL POLYGONS DATASET....this makes it into a shape file
camera_polygons<-SpatialPolygons(camera_polygons)
plot(camera_polygons)
# SPATIAL DATA.FRAME NEEDED FOR SIMULATION LATER .....this may have an error if you don't run it all at once
camera_polygons_df <- SpatialPolygonsDataFrame(Sr=camera_polygons,
data=camera_polygons_df,match.ID = TRUE)
#------------Finally assign pigs to the sites-------
# CALCULATE THE LOG(NUMBER OF PIGS IN EACH PATCH)...this is simulated so that larger patches have more pigs
patch_polys_df@data$y<- log(inputs$D)+log(patch_polys_df@data$patch_size_ha)
# EXPECTED NUMBER OF PIGS IN EACH PATCH
patch_polys_df@data$lambda<- exp(patch_polys_df@data$y)
# NUMBER OF PIGS IN EACH PATCH
patch_polys_df@data$N<- rpois(inputs$n_patches, patch_polys_df@data$lambda)
#----------------Lastly simulate the data with the defined areas and species abundances
patch_data<- lapply(seq_along(patch_polys),function(ii)
{
# SUBSET CAMERA A AND B FROM THE PATCH
A<-subset(camera_polygons_df, patch==ii&camera=="a")
B<-subset(camera_polygons_df, patch==ii&camera=="b")
# SHARED AREA BY CAMERA A AND B IN HECATARES
AB<- A-(A-B)
# EXTRACT AREAS FOR CAMERA A, CAMERA B, AND SHARED BY A AND B IN HECATARES
area_A<-sapply(slot(A, "polygons"), slot, "area")
area_B<-sapply(slot(B, "polygons"), slot, "area")
area_AB<- sapply(slot(AB, "polygons"), slot, "area")
# CALCULATE TOTAL AREA FOR EACH CAMERA IN HECATARES
total_camera_areas<- area_A-area_AB+area_B-area_AB + area_AB
outside_area<- patch_polys_df$patch_size_ha[ii]-sum(total_camera_areas)
p<- c(outside_area,total_camera_areas)/sum(c(outside_area,total_camera_areas))
# RANDOMLY ASSIGN A PIG TO OUTSIDE OR A CAMERA PAIR (ASSUMES RANDOM DISTRIBUTION) - Not a great assumption since animal trails were targeted. This could affect the simulations.
# NUMBER OF PIGS IN EACH LOCATION (OUTSIDE, SITE 1, ... SITE N W/IN PATCH)
Z<-rmultinom(patch_polys_df$num_minutes[ii],
patch_polys_df$N[ii],
prob=p)
# DROP THE NUMBER OF CRITTERS THAT WERE OUTSIDE (I.E., NOT AVAILIBLE FOR CAPTURE)
Z<-Z[-1,]
# DROP THE MINUTES THAT THERE WERE NO CAPTURES
indx<- which(colSums(Z)>0)
# NOW FOR EACH PIG THAT WAS CAPTURED ON CAMERA--ASSIGN IT TO A STATE WITHIN THE CAMERA POLYGON
# MATRIX [SITE,STATE] OF WEIGHTS FOR EACH ARE ASSIGNED
wghts<-lapply(seq_along(total_camera_areas),function(x)
{
w<- c(area_A[x]-area_AB[x],area_B[x]-area_AB[x],area_AB[x])/total_camera_areas[x]
return(w)
})
wghts<-as.data.frame(do.call("rbind",wghts)) # SHOULD ALL BE THE SAME BUT BUILDS THE FLEXIBLITY OF VARIABLE DISTANCES BETWEEN CAMERAS @ A SITE
names(wghts)<- c("A","B","AB")
wghts$site<-names(area_A)
# ASSIGN AN INVIDUAL A TRUE CAPTURE STATE AND AN OBSERVED STATE
sites_within_patch_data<-lapply(indx,function(x)
{
hits<- which(Z[,x]>0)
n_captured<-Z[hits,x]
# EXPAND DATASET TO REPRESENT INDVIDUALS
tmp<- data.frame(patch= ii,
minute= x,
site=rep(names(Z[hits,x]),n_captured),
n_captured=rep(1,sum(n_captured)))
# RANDOMLY ASSIGN A STATE (1=Camera A but behind B, 2=Camera B but behind A, 3=between camera a and b)
tmp<-merge(tmp,wghts,by="site",all.x=TRUE)
tmp$state<-NA
tmp$capture_a<-NA # CAPTURED ON CAMERA A?
tmp$capture_b<-NA # CAPTURED ON CAMERA B?
for(i in 1:nrow(tmp))
{
# TRUE STATE
tmp$state[i]<- which(rmultinom(1,1,tmp[i,c(5:7)])==1)
# OBSERVATION STATE
if(tmp$state[i]==1)
{
tmp$capture_a[i]<-rbinom(1,1,inputs$p)
tmp$capture_b[i]<-0
}
if(tmp$state[i]==2)
{
tmp$capture_a[i]<-0;
tmp$capture_b[i]<-rbinom(1,1,inputs$p)
}
if(tmp$state[i]==3)
{
tmp$capture_a[i]<-rbinom(1,1,inputs$p)
tmp$capture_b[i]<-rbinom(1,1,inputs$p)
}
}
return(tmp)
})
out<-do.call("rbind",sites_within_patch_data)
return(out)
})
all_dat<-do.call("rbind",patch_data)
rm(list=ls())
#simulate some data
mean1=3
mean2=7
nobs=1000
sd1=1.2
y1=rnorm(nobs,mean=mean1,sd=sd1)
y2=rnorm(nobs,mean=mean2,sd=sd1)
#look at data
yjoin=c(y1,y2)
hist(yjoin,probability = T)
tmp=density(yjoin)
lines(tmp$x,tmp$y)
#look at residuals
resjoin=c(y1-mean1,y2-mean2)
hist(resjoin,probability=T)
tmp=density(resjoin)
lines(tmp$x,tmp$y)
seq1=seq(from=min(resjoin),to=max(resjoin),length.out=100)
media1=mean(resjoin)
sd1=sd(resjoin)
lines(seq1,dnorm(seq1,mean=media1,sd=sd1),col='red')
b=2
n=100
media=seq(from=0.1,to=10,length.out=n)
a=b*media
var1=a/(b^2)
plot(media,var1)
b=0.2
n=100
media=seq(from=0.1,to=10,length.out=n)
a=b*media
var1=a/(b^2)
plot(media,var1)
seq1=seq(from=-10,to=10,length.out=1000)
y=dt(seq1,df=4)
plot(seq1,y)
seq1=seq(from=-10,to=10,length.out=1000)
y=dt(seq1,df=4)
plot(seq1,y,type='l')
y=dt(seq1,df=100)
lines(seq1,y,col='red')
seq1=seq(from=-10,to=10,length.out=1000)
y=dt(seq1,df=4)
plot(seq1,y,type='l')
abline(v=2.5,col='grey')
1-pt(2.5,df=4)
abline(v=2,col='grey')
1-pt(2,df=4)
seq1=seq(from=-10,to=10,length.out=1000)
y=dt(seq1,df=4)
plot(seq1,y,type='l')
abline(v=1.5,col='grey')
1-pt(1.5,df=4)
y=dt(seq1,df=100)
lines(seq1,y,col='red')
1-pt(1.5,df=100)
seq1=seq(from=-10,to=10,length.out=1000)
y=dt(seq1,df=4)
plot(seq1,y,type='l')
tval=2
abline(v=tval,col='grey')
1-pt(tval,df=4)
y=dt(seq1,df=100)
lines(seq1,y,col='red')
1-pt(tval,df=100)
rm(list=ls())
library('foreach')
library('parallel')
?foreach
nobs=100
x=seq(from=0,to=100,length.out=nobs)
b0=1
b1=2
y=rnorm(nobs,mean=b0+b1*x,sd=1)
plot(x,y)
nobs=100
x=seq(from=0,to=100,length.out=nobs)
b0=1
b1=2
y=rnorm(nobs,mean=b0+b1*x,sd=10)
plot(x,y)
cor(dat)[1,2]
dat=data.frame(x=x,y=y)
cor(dat)[1,2]
nobs=100
x=seq(from=0,to=100,length.out=nobs)
b0=1
b1=1
y=rnorm(nobs,mean=b0+b1*x,sd=10)
plot(x,y)
dat=data.frame(x=x,y=y)
cor(dat)[1,2]
nobs=100
x=seq(from=0,to=100,length.out=nobs)
b0=1
b1=0.2
y=rnorm(nobs,mean=b0+b1*x,sd=10)
plot(x,y)
dat=data.frame(x=x,y=y)
cor(dat)[1,2]
mod=lm(y~x,data=dat)
mod
summary(mod)
nobs=100
x=seq(from=0,to=100,length.out=nobs)
b0=1
b1=-0.2
y=rnorm(nobs,mean=b0+b1*x,sd=10)
plot(x,y)
dat=data.frame(x=x,y=y)
cor(dat)[1,2]
mod=lm(y~x,data=dat)
summary(mod)
cor(dat)[1,2]^2
?cor
dat=data.frame(x=x,y=y,method='pearson')
cor(dat)[1,2]
nobs=100
x=seq(from=0,to=100,length.out=nobs)
b0=1
b1=-0.2
y=rnorm(nobs,mean=b0+b1*x,sd=10)
plot(x,y)
#calculate correlation
dat=data.frame(x=x,y=y,method='pearson')
cor(dat)[1,2]
dat=data.frame(x=x,y=y)
cor(dat,method='pearson')[1,2]
mod=lm(y~x,data=dat)
summary(mod)
cor(dat)[1,2]^2
#This code is based on "A primer on regression splines"
## $Id: spline_primer.Rnw,v 1.29 2013/01/22 17:43:52 jracine Exp jracine $
## April 23 2011. The code below is based upon an illustration that
## can be found in http://www.stat.tamu.edu/~sinha/research/note1.pdf
## by Dr. Samiran Sinha (Department of Statistics, Texas A&M). I am
## solely to blame for any errors and can be contacted at
## racinej@mcmaster.ca (Jeffrey S. Racine).
## This function is a (simplified) R implementation of the bs()
## function in the splines library and illustrates how the Cox-de Boor
## recursion formula is used to construct B-splines.
basis <- function(x, degree, i, knots) {
if(degree == 0){
B <- ifelse((x >= knots[i]) & (x < knots[i+1]), 1, 0)
} else {
if((knots[degree+i] - knots[i]) == 0) {
alpha1 <- 0
} else {
alpha1 <- (x - knots[i])/(knots[degree+i] - knots[i])
}
if((knots[i+degree+1] - knots[i+1]) == 0) {
alpha2 <- 0
} else {
alpha2 <- (knots[i+degree+1] - x)/(knots[i+degree+1] - knots[i+1])
}
B <- alpha1*basis(x, (degree-1), i, knots) + alpha2*basis(x, (degree-1), (i+1), knots)
}
return(B)
}
bs <- function(x, degree=3, interior.knots=NULL, intercept=FALSE, Boundary.knots = c(0,1)) {
Boundary.knots <- sort(Boundary.knots)
interior.knots.sorted <- sort(interior.knots)
knots <- c(rep(Boundary.knots[1], (degree+1)), interior.knots.sorted, rep(Boundary.knots[2], (degree+1)))
K <- length(interior.knots) + degree + 1
B.mat <- matrix(0,length(x),K)
for(j in 1:K) B.mat[,j] <- basis(x, degree, j, knots)
if(any(x == Boundary.knots[2])) B.mat[x == Boundary.knots[2], K] <- 1
if(intercept == FALSE) {
return(B.mat[,-1])
} else {
return(B.mat)
}
}
#look at what this looks likes
par(mfrow = c(2,1))
n <- 1000
x <- seq(0, 1, length=n)
B <- bs(x, degree=3, intercept = T, interior.knots=c(0.25,0.5,0.75),Boundary.knots=c(0, 1))
dim(B)
plot(NA,NA,xlim=range(x),ylim=range(B))
for (i in 1:ncol(B)) lines(x,B[,i],col=i)
abline(v=c(0.25,0.5,0.75),col='grey')
plot(NA,NA,xlim=range(x),ylim=range(B))
for (i in 1:ncol(B)) lines(x,B[,i],col=i)
abline(v=c(0.25,0.5,0.75),col='grey')
par(mfrow = c(2,1))
n <- 1000
x <- seq(0, 1, length=n)
B <- bs(x, degree=2, intercept = T, interior.knots=c(0.25,0.5,0.75),Boundary.knots=c(0, 1))
dim(B)
plot(NA,NA,xlim=range(x),ylim=range(B))
for (i in 1:ncol(B)) lines(x,B[,i],col=i)
abline(v=c(0.25,0.5,0.75),col='grey')
par(mfrow = c(1,1))
n <- 1000
x <- seq(0, 1, length=n)
B <- bs(x, degree=2, intercept = T, interior.knots=c(0.25,0.5,0.75),Boundary.knots=c(0, 1))
dim(B)
plot(NA,NA,xlim=range(x),ylim=range(B))
for (i in 1:ncol(B)) lines(x,B[,i],col=i)
abline(v=c(0.25,0.5,0.75),col='grey')
B <- bs(x, degree=3, intercept = T, interior.knots=c(0.25,0.5,0.75),Boundary.knots=c(0, 1))
dim(B)
plot(NA,NA,xlim=range(x),ylim=range(B))
for (i in 1:ncol(B)) lines(x,B[,i],col=i)
abline(v=c(0.25,0.5,0.75),col='grey')
rm(list=ls(all=TRUE))
#root path
setwd('U:\\independent studies\\LIDAR Tanguro\\LidarLDA_MS')
#get data
phi.t3=read.csv('simul\\fake data\\phi3.csv')
phi.t5=read.csv('simul\\fake data\\phi5.csv')
phi.e3=read.csv('simul\\results\\phi3.csv')[1:3,];
phi.e5=read.csv('simul\\results\\phi5.csv')[1:5,];
seq1=c(2,1,3,5,4)
phi.e5=phi.e5[seq1,]
#make graphs for ncluster=3
cores3=c('green','red','cyan')
rango=range(c(phi.t3,phi.e3))
png('simul\\derived\\scatterplot phi3.png',width=700,height=700)
par(mfrow=c(1,1),mar=c(4,6,1,1))
plot(NA,NA,ylim=rango,xlim=rango,xlab='True',ylab='Estimated',
cex.lab=3,cex.axis=2.5,cex=2,pch=19,
main='',cex.main=4)
for (i in 1:3) points(phi.t3[i,],phi.e3[i,],col=cores3[i],pch=19,cex=2)
rango1=c(0,1)
lines(rango1,rango1,col='grey',lwd=3)
fim=data.frame(true1=unlist(phi.t3),
estim=unlist(phi.e3))
r=cor(fim)[1,2]
text(rango[1]+0.05,rango[2],round(r,3),cex=3)
legend(0.6,0.25,pch=19,col=cores3,
paste0('Cluster ',1:3),cex=2)
dev.off()
#make graphs for ncluster=5
cores5=c('green','red','cyan','orange','blue')
rango=range(c(phi.e5,phi.t5))
png('simul\\derived\\scatterplot phi5.png',width=700,height=700)
par(mfrow=c(1,1),mar=c(4,6,1,1))
plot(NA,NA,ylim=rango,xlim=rango,xlab='True',ylab='Estimated',
cex.lab=3,cex.axis=2.5,cex=2,pch=19,
main='',cex.main=4)
for (i in 1:5){
points(phi.t5[i,],phi.e5[i,],col=cores5[i],pch=19,cex=2)
}
rango1=c(0,1)
lines(rango1,rango1,col='grey',lwd=3)
fim=data.frame(true1=unlist(phi.t5),
estim=unlist(phi.e5))
r=cor(fim)[1,2]
text(rango[1]+0.05,rango[2],round(r,3),cex=3)
legend(0.6,0.3,pch=19,col=cores5,
paste0('Cluster ',1:5),cex=2)
dev.off()
rm(list=ls(all=TRUE))
#root path
setwd('U:\\independent studies\\LIDAR Tanguro\\LidarLDA_MS')
phi.t3=read.csv('simul\\fake data\\phi3.csv')
phi.t5=read.csv('simul\\fake data\\phi5.csv')
nspp=ncol(phi.t3)
cores=c('green','red','cyan')
png('simul\\derived\\phi comparison3.png',width=700,height=1000)
par(mfrow=c(3,1),mar=c(3,3,1,1),oma=c(4,4,0,0))
for (i in 1:3){
plot(1:nspp,phi.t3[i,],type='h',ylim=c(0,1),xlab='',ylab='',main='',
cex.axis=2,lwd=3,col=cores[i])
text(2,0.9,i,cex=5)
# for (j in 1:nspp){
#   lines(rep(j,2)+0.1,c(0,phi.e3[i,j]),col='red')
# }
}
# legend(20,0.9,col=c('black','red'),c('True','Estimated'),lty=1,cex=2)
mtext(side=1,at=0.5,outer=T,line=1,'Height (m)',cex=2)
mtext(side=2,at=0.5,outer=T,line=1,'Absorptance probability',cex=2)
dev.off()
cores=c('green','red','cyan','blue','orange')
png('simul\\derived\\phi comparison5.png',width=700,height=1000)
par(mfrow=c(5,1),mar=c(3,3,1,1),oma=c(4,4,0,0))
for (i in 1:5){
plot(1:nspp,phi.t5[i,],type='h',ylim=c(0,1),xlab='',ylab='',main='',
cex.axis=2,lwd=3,col=cores[i])
text(2,0.9,i,cex=5)
# for (j in 1:nspp){
#   lines(rep(j,2)+0.1,c(0,phi.e5[i,j]),col='red')
# }
}
# legend(20,0.9,col=c('black','red'),c('True','Estimated'),lty=1,cex=2)
mtext(side=1,at=0.5,outer=T,line=1,'Height (m)',cex=2)
mtext(side=2,at=0.5,outer=T,line=1,'Absorptance probability',cex=2)
dev.off()
rm(list=ls())
library(ggplot2)    #ggplot2_3.3.3
#root path
setwd('U:\\independent studies\\LIDAR Tanguro\\LidarLDA_MS')
#get true parameter values
combo3=read.csv('simul\\fake data\\theta3.csv')
combo5=read.csv('simul\\fake data\\theta5.csv')
res3=ggplot(data=combo3,aes(x=x,y=y)) +
geom_tile(alpha = combo3$y1, fill='green') +
geom_tile(alpha = combo3$y2, fill='red') +
geom_tile(alpha = combo3$y3, fill='cyan') +
geom_contour(aes(x=x, y=y, z = topo))+
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
axis.title.y=element_blank(),
axis.text.y=element_blank(),
axis.ticks.y=element_blank()) +
xlab('')+ylab('')
res5=ggplot(data=combo5,aes(x=x,y=y)) +
geom_tile(alpha = combo5$y1, fill='green') +
geom_tile(alpha = combo5$y2, fill='red') +
geom_tile(alpha = combo5$y3, fill='cyan') +
geom_tile(alpha = combo5$y4, fill='blue') +
geom_tile(alpha = combo5$y5, fill='orange') +
geom_contour(aes(x=x, y=y, z = topo))+
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
axis.title.y=element_blank(),
axis.text.y=element_blank(),
axis.ticks.y=element_blank()) +
xlab('')+ylab('')
ggsave(file='simul\\derived\\map true3.jpeg',res3,width=7,height=7)
ggsave(file='simul\\derived\\map true5.jpeg',res3,width=7,height=7)
rm(list=ls())
library(ggplot2)    #ggplot2_3.3.3
#root path
setwd('U:\\independent studies\\LIDAR Tanguro\\LidarLDA_MS')
#get true parameter values
combo3=read.csv('simul\\fake data\\theta3.csv')
combo5=read.csv('simul\\fake data\\theta5.csv')
#plot spatial distribution
res3=ggplot(data=combo3,aes(x=x,y=y)) +
geom_tile(alpha = combo3$y1, fill='green') +
geom_tile(alpha = combo3$y2, fill='red') +
geom_tile(alpha = combo3$y3, fill='cyan') +
geom_contour(aes(x=x, y=y, z = topo))+
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
axis.title.y=element_blank(),
axis.text.y=element_blank(),
axis.ticks.y=element_blank()) +
xlab('')+ylab('')
res5=ggplot(data=combo5,aes(x=x,y=y)) +
geom_tile(alpha = combo5$y1, fill='green') +
geom_tile(alpha = combo5$y2, fill='red') +
geom_tile(alpha = combo5$y3, fill='cyan') +
geom_tile(alpha = combo5$y4, fill='blue') +
geom_tile(alpha = combo5$y5, fill='orange') +
geom_contour(aes(x=x, y=y, z = topo))+
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
axis.title.y=element_blank(),
axis.text.y=element_blank(),
axis.ticks.y=element_blank()) +
xlab('')+ylab('')
#export plots
ggsave(file='simul\\derived\\map true3.jpeg',res3,width=7,height=7)
ggsave(file='simul\\derived\\map true5.jpeg',res5,width=7,height=7)
rm(list=ls())
library(ggplot2)   #ggplot2_3.3.3
#root path
setwd('U:\\independent studies\\LIDAR Tanguro\\LidarLDA_MS')
#get structure of original table
combo3=read.csv('simul\\fake data\\theta3.csv')
tmp=sample(1:3,size=nrow(combo3),replace=T)
combo3$Cluster=as.factor(tmp)
combo5=read.csv('simul\\fake data\\theta5.csv')
tmp=sample(1:5,size=nrow(combo5),replace=T)
combo5$Cluster=as.factor(tmp)
cores=c('green','red','cyan')
res3=ggplot(data=combo3,aes(x=x,y=y,fill=Cluster))+
geom_tile() +
scale_fill_manual(values = cores)
res3
cores=c('green','red','cyan','blue','orange')
res5=ggplot(data=combo5,aes(x=x,y=y,fill=Cluster))+
geom_tile() +
scale_fill_manual(values = cores)
res5
rm(list=ls())
library(ggplot2)   #ggplot2_3.3.3
#root path
setwd('U:\\independent studies\\LIDAR Tanguro\\LidarLDA_MS')
#get structure of original table
combo3=read.csv('simul\\fake data\\theta3.csv')
tmp=sample(1:3,size=nrow(combo3),replace=T)
combo3$Cluster=as.factor(tmp)
combo5=read.csv('simul\\fake data\\theta5.csv')
tmp=sample(1:5,size=nrow(combo5),replace=T)
combo5$Cluster=as.factor(tmp)
#get legends
cores=c('green','red','cyan')
res3=ggplot(data=combo3,aes(x=x,y=y,fill=Cluster))+
geom_tile() +
scale_fill_manual(values = cores)
res3
cores=c('green','red','cyan','blue','orange')
res5=ggplot(data=combo5,aes(x=x,y=y,fill=Cluster))+
geom_tile() +
scale_fill_manual(values = cores)
res5
#export results
ggsave(file='simul\\derived\\map true3legend.jpeg', res3,width=7,height=7)
ggsave(file='simul\\derived\\map true5legend.jpeg', res5,width=7,height=7)
